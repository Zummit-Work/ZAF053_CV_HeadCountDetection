{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4ad9bec-08bd-4f6f-a001-6479ded59885",
   "metadata": {},
   "source": [
    "# **MediaPipe**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fcfff1-48c2-4447-88b5-26b86c6ff54b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **From official site**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dbae35-613c-4caa-a563-08fd923065b1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "    import cv2\n",
    "    import mediapipe as mp\n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "\n",
    "    # For static images:\n",
    "    IMAGE_FILES = ['sample_image.jpg']\n",
    "\n",
    "    with mp_face_detection.FaceDetection(\n",
    "        model_selection=1,\n",
    "        min_detection_confidence=0.5\n",
    "\n",
    "    ) as face_detection:\n",
    "\n",
    "        for idx, file in enumerate(IMAGE_FILES):\n",
    "            image = cv2.imread(file)\n",
    "            # Convert the BGR image to RGB and process it with MediaPipe Face Detection.\n",
    "            results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "            # Draw face detections of each face.\n",
    "            if not results.detections:\n",
    "                continue\n",
    "\n",
    "            annotated_image = image.copy()\n",
    "\n",
    "            for detection in results.detections:\n",
    "                print('Nose tip:')\n",
    "\n",
    "                print(\n",
    "                    mp_face_detection.get_key_point(\n",
    "                        detection,\n",
    "                        mp_face_detection.FaceKeyPoint.NOSE_TIP\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                mp_drawing.draw_detection(annotated_image, detection)\n",
    "\n",
    "            cv2.imwrite('A' + str(idx) + '.png', annotated_image)\n",
    "            #cv2.imwrite('/tmp/annotated_image' + str(idx) + '.png', annotated_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # For webcam input:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    with mp_face_detection.FaceDetection(\n",
    "        model_selection=0,\n",
    "        min_detection_confidence=0.5\n",
    "    ) as face_detection:\n",
    "\n",
    "        while cap.isOpened():\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                print(\"Ignoring empty camera frame.\")\n",
    "                # If loading a video, use 'break' instead of 'continue'.\n",
    "                continue\n",
    "\n",
    "            # To improve performance, optionally mark the image as not writeable to\n",
    "            # pass by reference.\n",
    "            image.flags.writeable = False\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = face_detection.process(image)\n",
    "\n",
    "            # Draw the face detection annotations on the image.\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            if results.detections:\n",
    "                for detection in results.detections:\n",
    "                    mp_drawing.draw_detection(image, detection)\n",
    "\n",
    "            # Flip the image horizontally for a selfie-view display.\n",
    "            cv2.imshow('MediaPipe Face Detection', cv2.flip(image, 1))\n",
    "\n",
    "            if cv2.waitKey(5) & 0xFF == 27:\n",
    "                break\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    # Destroy all the windows\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de526d23-f6b8-465d-869d-546f472a8994",
   "metadata": {},
   "source": [
    "### Store annotated Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8e9b286-25f3-4497-a906-b7b1f989bcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_image(img_name_list):\n",
    "    import cv2\n",
    "    import mediapipe as mp\n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    \n",
    "\n",
    "    with mp_face_detection.FaceDetection(\n",
    "        model_selection=1,\n",
    "        min_detection_confidence=0.5\n",
    "\n",
    "    ) as face_detection:\n",
    "\n",
    "        for idx, file in enumerate(img_name_list):\n",
    "            image = cv2.imread(file)\n",
    "            # Convert the BGR image to RGB and process it with MediaPipe Face Detection.\n",
    "            results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "            # Draw face detections of each face.\n",
    "            if not results.detections:\n",
    "                continue\n",
    "\n",
    "            annotated_image = image.copy()\n",
    "\n",
    "            for detection in results.detections:\n",
    "                print('Nose tip:')\n",
    "\n",
    "                print(\n",
    "                    mp_face_detection.get_key_point(\n",
    "                        detection,\n",
    "                        mp_face_detection.FaceKeyPoint.NOSE_TIP\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                mp_drawing.draw_detection(annotated_image, detection)\n",
    "\n",
    "            cv2.imwrite( file.split('.')[0] + '_annotated.png' , annotated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea28a3e1-f7ee-4fbc-b11e-ea044057dd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = ['sample_image.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d59d3abd-842f-47c8-8695-98e452f4fd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nose tip:\n",
      "x: 0.44583046436309814\n",
      "y: 0.4802980422973633\n",
      "\n",
      "Nose tip:\n",
      "x: 0.5580391883850098\n",
      "y: 0.48664039373397827\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mediapipe_image(img_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f528be15-4fa8-48a4-aee3-75e65263a0fe",
   "metadata": {},
   "source": [
    "### Show and store annotated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5a6195a-1386-4081-a9fa-edc447757e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_image_1(img_name_list):\n",
    "    import cv2\n",
    "    import mediapipe as mp\n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    \n",
    "\n",
    "    with mp_face_detection.FaceDetection(\n",
    "        model_selection=1,\n",
    "        min_detection_confidence=0.5\n",
    "\n",
    "    ) as face_detection:\n",
    "\n",
    "        for idx, file in enumerate(img_name_list):\n",
    "            image = cv2.imread(file)\n",
    "            # Convert the BGR image to RGB and process it with MediaPipe Face Detection.\n",
    "            results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "            # Draw face detections of each face.\n",
    "            if not results.detections:\n",
    "                continue\n",
    "\n",
    "            annotated_image = image.copy()\n",
    "\n",
    "            #print( list(results.detections) )\n",
    "            \n",
    "            # print the coordinates of face key points\n",
    "            for i,detection in enumerate( tuple(results.detections )):\n",
    "                print('DETECTION ',i)\n",
    "                print('  Nose tip:')\n",
    "                print(\n",
    "                    mp_face_detection.get_key_point(\n",
    "                        detection,\n",
    "                        # nose tip\n",
    "                        mp_face_detection.FaceKeyPoint.NOSE_TIP\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "                print('  Mouth center:')\n",
    "                print(\n",
    "                    mp_face_detection.get_key_point(\n",
    "                        detection,\n",
    "                        # mouth center\n",
    "                        mp_face_detection.FaceKeyPoint.MOUTH_CENTER\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                mp_drawing.draw_detection(annotated_image, detection)\n",
    "\n",
    "            cv2.imwrite( file.split('.')[0] + '_annotated.png' , annotated_image)\n",
    "            cv2.imshow(file, annotated_image)\n",
    "            cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9836be32-b68b-42cc-a086-2fd23f5daa64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETECTION  0\n",
      "  Nose tip:\n",
      "x: 0.44583046436309814\n",
      "y: 0.4802980422973633\n",
      "\n",
      "  Mouth center:\n",
      "x: 0.445222944021225\n",
      "y: 0.49528729915618896\n",
      "\n",
      "DETECTION  1\n",
      "  Nose tip:\n",
      "x: 0.5580391883850098\n",
      "y: 0.48664039373397827\n",
      "\n",
      "  Mouth center:\n",
      "x: 0.5629162788391113\n",
      "y: 0.5090557336807251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mediapipe_image_1(['sample_image.jpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46d16b-9145-4064-8b5b-7b81d0454ad3",
   "metadata": {},
   "source": [
    "### Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a75de10-8775-470a-9dcc-99ccda78f50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_webcam(my_model_selection=0, my_min_detection_confidence=0.5):\n",
    "    '''\n",
    "    Code from official website\n",
    "    '''\n",
    "    \n",
    "    import cv2\n",
    "    import mediapipe as mp\n",
    "    from warnings import warn\n",
    "    \n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    # For webcam input:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    with mp_face_detection.FaceDetection(\n",
    "        model_selection = my_model_selection,\n",
    "        min_detection_confidence = my_min_detection_confidence\n",
    "    ) as face_detection:\n",
    "\n",
    "        while cap.isOpened():\n",
    "            \n",
    "            # end feed\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "                \n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                warn('Webcam not detected.')\n",
    "                break\n",
    "                #print(\"Webcam not detected.\")\n",
    "                # If loading a video, use 'break' instead of 'continue'.\n",
    "                #continue\n",
    "\n",
    "            # To improve performance, optionally mark the image as not writeable to\n",
    "            # pass by reference.\n",
    "            image.flags.writeable = False\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = face_detection.process(image)\n",
    "\n",
    "            # Draw the face detection annotations on the image.\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            if results.detections:\n",
    "                for detection in results.detections:\n",
    "                    mp_drawing.draw_detection(image, detection)\n",
    "\n",
    "            # Flip the image horizontally for a selfie-view display.\n",
    "            cv2.imshow('MediaPipe Face Detection', cv2.flip(image, 1))\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    # Destroy all the windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "931f9f94-9275-421b-b99a-b03f34f6da3d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "mediapipe_webcam(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455422c4-f2dd-4e80-a63d-44a751e83cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570d8c4d-a320-411a-8136-fe4409eae012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b1b7e9c-6121-497e-b874-4f9829f27184",
   "metadata": {},
   "source": [
    "### Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4bd6cc3-1327-4147-93b0-c9dab9b46502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_video(filepath = 'C:/Users/afzal/Downloads/sample.mp4', my_model_selection=0, my_min_detection_confidence=0.5):\n",
    "    \n",
    "    '''\n",
    "    Code from official website\n",
    "    '''\n",
    "    import cv2\n",
    "    import mediapipe as mp\n",
    "    from warnings import warn\n",
    "    \n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    # For webcam input:\n",
    "    cap = cv2.VideoCapture(filepath)\n",
    "\n",
    "    with mp_face_detection.FaceDetection(\n",
    "        model_selection = my_model_selection,\n",
    "        min_detection_confidence = my_min_detection_confidence\n",
    "    ) as face_detection:\n",
    "\n",
    "        while cap.isOpened():\n",
    "            \n",
    "            # end feed\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "                \n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                warn('File not found.')\n",
    "                break\n",
    "                #print(\"Webcam not detected.\")\n",
    "                # If loading a video, use 'break' instead of 'continue'.\n",
    "                #continue\n",
    "\n",
    "            # To improve performance, optionally mark the image as not writeable to\n",
    "            # pass by reference.\n",
    "            image.flags.writeable = False\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = face_detection.process(image)\n",
    "\n",
    "            # Draw the face detection annotations on the image.\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            if results.detections:\n",
    "                for detection in results.detections:\n",
    "                    mp_drawing.draw_detection(image, detection,)\n",
    "\n",
    "            cv2.imshow('MediaPipe Face Detection', image)\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    # Destroy all the windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db71b0f6-c4f0-4061-8e25-17f322a49459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d27d795-bf22-4ea1-86c8-81c68f5d2140",
   "metadata": {},
   "source": [
    "#### 144p enlarged video checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "258a7978-b347-4db1-ba93-f27643b88f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:/Users/afzal/Downloads/sample_144_enlarged.mp4'\n",
    "\n",
    "mediapipe_video(filepath=filepath, my_model_selection=1, my_min_detection_confidence=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58864615-6a51-4a1f-86d1-1aaa038b7f38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5794d9a7-9d4b-4f64-b8c7-f3f1e4820f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e870e893-7c33-4846-9ea2-2e39974417ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8e3f883-89eb-45a9-9910-4182e336017e",
   "metadata": {},
   "source": [
    "# Facemesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0bb2ef5-31c2-42c6-9b32-14c3429a078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def facemesh(file_path=None):\n",
    "    import cv2\n",
    "    import mediapipe as mp\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_drawing_styles = mp.solutions.drawing_styles\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "    # # For static images:\n",
    "    # IMAGE_FILES = []\n",
    "    # drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "    # with mp_face_mesh.FaceMesh(\n",
    "    #     static_image_mode=True,\n",
    "    #     max_num_faces=1,\n",
    "    #     refine_landmarks=True,\n",
    "    #     min_detection_confidence=0.5) as face_mesh:\n",
    "    #   for idx, file in enumerate(IMAGE_FILES):\n",
    "    #     image = cv2.imread(file)\n",
    "    #     # Convert the BGR image to RGB before processing.\n",
    "    #     results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    #     # Print and draw face mesh landmarks on the image.\n",
    "    #     if not results.multi_face_landmarks:\n",
    "    #       continue\n",
    "    #     annotated_image = image.copy()\n",
    "    #     for face_landmarks in results.multi_face_landmarks:\n",
    "    #       print('face_landmarks:', face_landmarks)\n",
    "    #       mp_drawing.draw_landmarks(\n",
    "    #           image=annotated_image,\n",
    "    #           landmark_list=face_landmarks,\n",
    "    #           connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "    #           landmark_drawing_spec=None,\n",
    "    #           connection_drawing_spec=mp_drawing_styles\n",
    "    #           .get_default_face_mesh_tesselation_style())\n",
    "    #       mp_drawing.draw_landmarks(\n",
    "    #           image=annotated_image,\n",
    "    #           landmark_list=face_landmarks,\n",
    "    #           connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "    #           landmark_drawing_spec=None,\n",
    "    #           connection_drawing_spec=mp_drawing_styles\n",
    "    #           .get_default_face_mesh_contours_style())\n",
    "    #       mp_drawing.draw_landmarks(\n",
    "    #           image=annotated_image,\n",
    "    #           landmark_list=face_landmarks,\n",
    "    #           connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "    #           landmark_drawing_spec=None,\n",
    "    #           connection_drawing_spec=mp_drawing_styles\n",
    "    #           .get_default_face_mesh_iris_connections_style())\n",
    "    #     cv2.imwrite('/tmp/annotated_image' + str(idx) + '.png', annotated_image)\n",
    "\n",
    "\n",
    "\n",
    "    # For webcam input:\n",
    "\n",
    "    drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "    \n",
    "    if file_path==None:\n",
    "        cap = cv2.VideoCapture(0)\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(file_path)\n",
    "\n",
    "    with mp_face_mesh.FaceMesh(\n",
    "        max_num_faces=5,\n",
    "        refine_landmarks=True,\n",
    "        min_detection_confidence=0.6,\n",
    "        min_tracking_confidence=0.6\n",
    "\n",
    "    ) as face_mesh:\n",
    "\n",
    "        while cap.isOpened():\n",
    "\n",
    "            success, image = cap.read()\n",
    "\n",
    "            if not success:\n",
    "                print(\"Ignoring empty camera frame.\")\n",
    "                # If loading a video, use 'break' instead of 'continue'.\n",
    "                continue\n",
    "\n",
    "            # To improve performance, optionally mark the image as not writeable to\n",
    "            # pass by reference.\n",
    "            image.flags.writeable = False\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = face_mesh.process(image)\n",
    "\n",
    "            # Draw the face mesh annotations on the image.\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            if results.multi_face_landmarks:\n",
    "                for face_landmarks in results.multi_face_landmarks:\n",
    "\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image=image,\n",
    "                        landmark_list=face_landmarks,\n",
    "                        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                        landmark_drawing_spec=None,\n",
    "                        connection_drawing_spec=mp_drawing_styles\n",
    "                        .get_default_face_mesh_tesselation_style()\n",
    "                    )\n",
    "\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image=image,\n",
    "                        landmark_list=face_landmarks,\n",
    "                        connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                        landmark_drawing_spec=None,\n",
    "                        connection_drawing_spec=mp_drawing_styles\n",
    "                        .get_default_face_mesh_contours_style()\n",
    "                    )\n",
    "\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image=image,\n",
    "                        landmark_list=face_landmarks,\n",
    "                        connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "                        landmark_drawing_spec=None,\n",
    "                        connection_drawing_spec=mp_drawing_styles\n",
    "                        .get_default_face_mesh_iris_connections_style()\n",
    "                    )\n",
    "\n",
    "            # Flip the image horizontally for a selfie-view display.\n",
    "            cv2.imshow(\n",
    "                'MediaPipe Face Mesh',\n",
    "                ( cv2.flip(image, 1) if file_path==None else image )\n",
    "            )\n",
    "\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54ddbbde-5168-483c-8856-c2da963da384",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:/Users/afzal/Downloads/sample.mp4'\n",
    "facemesh(file_path=filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10981da3-e384-4daf-bf9c-0fde4f0b5a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1d8448-9a5f-4216-ac2a-3825bc54d93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4c613a4-143e-4b71-8190-4e29cb9bbe39",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# **Unofficial**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f629e8-34ae-4987-a690-e5c28d407a41",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "165abc85-1e5f-436b-845c-2752fb7b31a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mediapipe_webcam(my_model_selection=0, my_min_detection_confidence=0.5):  \n",
    "    '''\n",
    "Webcam input\n",
    "Code from external site\n",
    "    '''\n",
    "    \n",
    "    import cv2\n",
    "    import mediapipe as mp\n",
    "    import time\n",
    "    import sys\n",
    "\n",
    "    # TAKE IN WEBCAM INPUT AND DETECT FACE\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    pTime = 0\n",
    "\n",
    "    mpFaceDetection = mp.solutions.face_detection\n",
    "    mpDraw = mp.solutions.drawing_utils\n",
    "    \n",
    "    faceDetection = mpFaceDetection.FaceDetection(\n",
    "        model_selection = my_model_selection,\n",
    "        min_detection_confidence = my_min_detection_confidence\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "        \n",
    "        success, img = cap.read()\n",
    "        \n",
    "        if success == False:\n",
    "            from warnings import warn\n",
    "            warn('Webcam not found.')\n",
    "            break\n",
    "            \n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = faceDetection.process(imgRGB)      \n",
    "\n",
    "        '''###############'''\n",
    "        #print(results.detections)\n",
    "        # sys.stdout.write(f'detections: { results.detections }\\r')\n",
    "        # sys.stdout.flush()\n",
    "        bbox= None\n",
    "        \n",
    "        if results.detections:\n",
    "            for id, detection in enumerate(results.detections):\n",
    "                # mpDraw.draw_detection(img, detection)\n",
    "                # print(id, detection)\n",
    "                # print(detection.score)\n",
    "                # print(detection.location_data.relative_bounding_box)\n",
    "                \n",
    "                bboxC = detection.location_data.relative_bounding_box\n",
    "                ih, iw, ic = img.shape\n",
    "                \n",
    "                bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                \n",
    "                cv2.rectangle(\n",
    "                    img,\n",
    "                    bbox,\n",
    "                    (255, 0, 255),\n",
    "                    2\n",
    "                )\n",
    "                \n",
    "                cv2.putText(\n",
    "                    img,\n",
    "                    f'{ int( detection.score[0] * 100 ) }%',\n",
    "                    (bbox[0], bbox[1] - 20),\n",
    "                    cv2.FONT_HERSHEY_PLAIN,\n",
    "                    2, \n",
    "                    (255, 0, 255),\n",
    "                    2\n",
    "                )\n",
    "\n",
    "                \n",
    "        '''##############'''\n",
    "        sys.stdout.write(f'Coordinates: {bbox}\\r')\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        \n",
    "        cTime = time.time()\n",
    "        fps = 1 / (cTime - pTime)\n",
    "        pTime = cTime\n",
    "        \n",
    "        cv2.putText(\n",
    "            img,\n",
    "            f'FPS: { int(fps) }',\n",
    "            (5, 30),\n",
    "            cv2.FONT_HERSHEY_PLAIN,\n",
    "            2,\n",
    "            (0, 255, 0),\n",
    "            2\n",
    "        )\n",
    "        \n",
    "        cv2.imshow(\"Image\", img)\n",
    "    \n",
    "    \n",
    "    # After the loop release the cap object\n",
    "    cap.release()\n",
    "    # Destroy all the windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6812f41c-3b4c-4512-ae5c-6354bd1e9ad0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates: (238, 270, 123, 123)\r"
     ]
    }
   ],
   "source": [
    "mediapipe_webcam(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176f2f53-0855-4f00-9d6d-9c65fe3b2663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188157ee-e6ca-47aa-aa70-ce65b5681f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2379180b-8458-4953-9fce-e6a766613791",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9541ff35-fce4-4e6d-8688-776e23c58609",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mediapipe_video(filepath = 'C:/Users/afzal/Downloads/sample.mp4'):  \n",
    "    '''\n",
    "Video file input\n",
    "    '''\n",
    "    \n",
    "    import cv2\n",
    "    import mediapipe as mp\n",
    "    import time\n",
    "    import sys\n",
    "\n",
    "    # TAKE IN VIDEO INPUT AND DETECT FACE\n",
    "    \n",
    "    cap = cv2.VideoCapture(filepath)\n",
    "    pTime = 0\n",
    "\n",
    "    mpFaceDetection = mp.solutions.face_detection\n",
    "    mpDraw = mp.solutions.drawing_utils\n",
    "    faceDetection = mpFaceDetection.FaceDetection(0.75)\n",
    "\n",
    "    while True:\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "        \n",
    "        success, img = cap.read()\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = faceDetection.process(imgRGB)      \n",
    "\n",
    "        '''################'''\n",
    "        #print(results.detections)\n",
    "        # sys.stdout.write(f'detections: { results.detections }\\r')\n",
    "        # sys.stdout.flush()\n",
    "        bbox= None\n",
    "        \n",
    "        if results.detections:\n",
    "            for id, detection in enumerate(results.detections):\n",
    "                # mpDraw.draw_detection(img, detection)\n",
    "                # print(id, detection)\n",
    "                # print(detection.score)\n",
    "                # print(detection.location_data.relative_bounding_box)\n",
    "                bboxC = detection.location_data.relative_bounding_box\n",
    "                ih, iw, ic = img.shape\n",
    "                bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                cv2.rectangle(img, bbox, (255, 0, 255), 2)\n",
    "                cv2.putText(img, f'{int(detection.score[0] * 100)}%',\n",
    "                            (bbox[0], bbox[1] - 20), cv2.FONT_HERSHEY_PLAIN,\n",
    "                            2, (255, 0, 255), 2)\n",
    "\n",
    "        \n",
    "        '''##############'''\n",
    "        sys.stdout.write(f'Coordinates: {bbox}\\r')\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        \n",
    "        cTime = time.time()\n",
    "        fps = 1 / (cTime - pTime)\n",
    "        pTime = cTime\n",
    "        \n",
    "        cv2.putText(\n",
    "            img,\n",
    "            f'FPS: {int(fps)}',\n",
    "            (5,30),\n",
    "            cv2.FONT_HERSHEY_PLAIN,\n",
    "            2,\n",
    "            (0, 255, 0),\n",
    "            2\n",
    "        )\n",
    "        \n",
    "        cv2.imshow(\"Image\", img)\n",
    "    \n",
    "    \n",
    "    # After the loop release the cap object\n",
    "    cap.release()\n",
    "    # Destroy all the windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57be6842-e211-4bd0-be86-80058643a9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a89a843-9146-4b01-bba8-ddcf35f7bf5b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates: (526, 140, 165, 165)\r"
     ]
    }
   ],
   "source": [
    "mediapipe_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dca9b16-d5e9-482f-98d5-96a2be0d6b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6a079d8-029e-47e1-8512-69d0dfee2b5e",
   "metadata": {},
   "source": [
    "### Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d326c1a-99d2-424b-b3fe-22dd8e1d5fd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mediapipe_hybrid(file_path=None, model=0, confidence=0.5):  \n",
    "    '''\n",
    "Webcam input\n",
    "Code from external site\n",
    "    '''\n",
    "    \n",
    "    import cv2\n",
    "    import mediapipe as mp\n",
    "    import time\n",
    "    import sys\n",
    "\n",
    "    if file_path == None:\n",
    "        cap = cv2.VideoCapture(0)\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(file_path)\n",
    "        \n",
    "    pTime = 0\n",
    "\n",
    "    mpFaceDetection = mp.solutions.face_detection\n",
    "    mpDraw = mp.solutions.drawing_utils\n",
    "    \n",
    "    faceDetection = mpFaceDetection.FaceDetection(\n",
    "        model_selection = model,\n",
    "        min_detection_confidence = confidence\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "        \n",
    "        success, img = cap.read()\n",
    "        \n",
    "        img = cv2.flip(img, 1) if file_path==None else img\n",
    "        \n",
    "        if success == False:\n",
    "            from warnings import warn\n",
    "            warn('Webcam not found.')\n",
    "            break\n",
    "            \n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = faceDetection.process(imgRGB)      \n",
    "\n",
    "        '''###############'''\n",
    "        #print(results.detections)\n",
    "        # sys.stdout.write(f'detections: { results.detections }\\r')\n",
    "        # sys.stdout.flush()\n",
    "        bbox= None\n",
    "        \n",
    "        if results.detections:\n",
    "            for id, detection in enumerate(results.detections):\n",
    "                # mpDraw.draw_detection(img, detection)\n",
    "                # print(id, detection)\n",
    "                # print(detection.score)\n",
    "                # print(detection.location_data.relative_bounding_box)\n",
    "                \n",
    "                bboxC = detection.location_data.relative_bounding_box\n",
    "                ih, iw, ic = img.shape\n",
    "                \n",
    "                bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                \n",
    "                cv2.rectangle(\n",
    "                    img,\n",
    "                    bbox,\n",
    "                    (255, 0, 255),\n",
    "                    2\n",
    "                )\n",
    "                \n",
    "                cv2.putText(\n",
    "                    img,\n",
    "                    f'{ int( detection.score[0] * 100 ) }%',\n",
    "                    (bbox[0], bbox[1] - 20),\n",
    "                    cv2.FONT_HERSHEY_PLAIN,\n",
    "                    2, \n",
    "                    (255, 0, 255),\n",
    "                    2\n",
    "                )\n",
    "\n",
    "                \n",
    "        '''##############'''\n",
    "        sys.stdout.write(f'Coordinates: {bbox}\\r')\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        \n",
    "        cTime = time.time()\n",
    "        fps = 1 / (cTime - pTime)\n",
    "        pTime = cTime\n",
    "        \n",
    "        cv2.putText(\n",
    "            img,\n",
    "            f'FPS: { int(fps) }',\n",
    "            (5, 30),\n",
    "            cv2.FONT_HERSHEY_PLAIN,\n",
    "            2,\n",
    "            (0, 255, 0),\n",
    "            2\n",
    "        )\n",
    "        \n",
    "        cv2.imshow(\"Image\", img)\n",
    "        \n",
    "        # cv2.imshow(\n",
    "        #     'MediaPipe Face count',\n",
    "        #     ( cv2.flip(img, 1) if file_path==None else img )\n",
    "        # )\n",
    "    \n",
    "    \n",
    "    # After the loop release the cap object\n",
    "    cap.release()\n",
    "    # Destroy all the windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec6c4ea2-2871-49fc-9a69-8033ca5718c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates: (57, 47, 95, 95)133))\r"
     ]
    }
   ],
   "source": [
    "filepath = 'C:/Users/afzal/Downloads/sample.mp4'\n",
    "\n",
    "mediapipe_hybrid(file_path=filepath ,model=1, confidence=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76d8cb8f-df33-46d4-84c5-d8b0dc24a729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates: (273, 234, 126, 126)\r"
     ]
    }
   ],
   "source": [
    "mediapipe_hybrid(model=1, confidence=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923a18bc-b519-4fc4-af71-7be06340904a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03749fd2-4ce1-481f-9764-11fe228f1dd3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73b1bfd-118a-4b61-9c60-0261fb9ed0ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, (216, 237, 144, 144), [0.8527037501335144]]] [1, (99, 103, 93, 93), [0.5043913722038269]]]]]]\r"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "\n",
    "class FaceDetector():\n",
    "    def __init__(self, minDetectionCon=0.5):\n",
    "\n",
    "        self.minDetectionCon = minDetectionCon\n",
    "\n",
    "        self.mpFaceDetection = mp.solutions.face_detection\n",
    "        self.mpDraw = mp.solutions.drawing_utils\n",
    "        self.faceDetection = self.mpFaceDetection.FaceDetection(self.minDetectionCon)\n",
    "\n",
    "    def findFaces(self, img, draw=True):\n",
    "\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        self.results = self.faceDetection.process(imgRGB)\n",
    "        # print(self.results)\n",
    "        bboxs = []\n",
    "        if self.results.detections:\n",
    "            for id, detection in enumerate(self.results.detections):\n",
    "                bboxC = detection.location_data.relative_bounding_box\n",
    "                ih, iw, ic = img.shape\n",
    "                bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), \\\n",
    "                       int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                bboxs.append([id, bbox, detection.score])\n",
    "                if draw:\n",
    "                    img = self.fancyDraw(img,bbox)\n",
    "\n",
    "                    cv2.putText(img, f'{int(detection.score[0] * 100)}%',\n",
    "                            (bbox[0], bbox[1] - 20), cv2.FONT_HERSHEY_PLAIN,\n",
    "                            2, (255, 0, 255), 2)\n",
    "        return img, bboxs\n",
    "\n",
    "    def fancyDraw(self, img, bbox, l=30, t=5, rt= 1):\n",
    "        x, y, w, h = bbox\n",
    "        x1, y1 = x + w, y + h\n",
    "\n",
    "        cv2.rectangle(img, bbox, (255, 0, 255), rt)\n",
    "        # Top Left  x,y\n",
    "        cv2.line(img, (x, y), (x + l, y), (255, 0, 255), t)\n",
    "        cv2.line(img, (x, y), (x, y+l), (255, 0, 255), t)\n",
    "        # Top Right  x1,y\n",
    "        cv2.line(img, (x1, y), (x1 - l, y), (255, 0, 255), t)\n",
    "        cv2.line(img, (x1, y), (x1, y+l), (255, 0, 255), t)\n",
    "        # Bottom Left  x,y1\n",
    "        cv2.line(img, (x, y1), (x + l, y1), (255, 0, 255), t)\n",
    "        cv2.line(img, (x, y1), (x, y1 - l), (255, 0, 255), t)\n",
    "        # Bottom Right  x1,y1\n",
    "        cv2.line(img, (x1, y1), (x1 - l, y1), (255, 0, 255), t)\n",
    "        cv2.line(img, (x1, y1), (x1, y1 - l), (255, 0, 255), t)\n",
    "        return img\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    import sys\n",
    "\n",
    "    # TAKE IN WEBCAM INPUT AND DETECT FACE\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    pTime = 0\n",
    "    detector = FaceDetector()\n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "        img, bboxs = detector.findFaces(img)\n",
    "        \n",
    "        sys.stdout.write(f'{bboxs}\\r')\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        cTime = time.time()\n",
    "        fps = 1 / (cTime - pTime)\n",
    "        pTime = cTime\n",
    "        cv2.putText(img, f'FPS: {int(fps)}', (20, 70), cv2.FONT_HERSHEY_PLAIN, 3, (0, 255, 0), 2)\n",
    "        cv2.imshow(\"Image\", img)\n",
    "        \n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "        \n",
    "    \n",
    "    # After the loop release the cap object\n",
    "    cap.release()\n",
    "    # Destroy all the windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d4fbf8-c87b-4446-bd5a-580fb6608c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813d7957-f971-4a50-9afc-848f554a10c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632f4e5d-e100-46f5-aa1e-411397d3752c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f5141b-75c2-42e6-a70b-bbb5388d26bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa6cd278-87bf-4494-8248-2d94b0d9a644",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# **Expt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22263cb8-126e-4874-817f-474c930d2e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0762573-4fbd-445c-9f06-d5f360937453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d8d4e88-8dd7-46a2-a9e6-9681f174026a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "filepath = 'C:/Users/afzal/Pictures/dataset/train/image_data/'\n",
    "\n",
    "img = cv.imread(filepath+'10001.jpg')\n",
    "\n",
    "cv.imshow('a window',img)\n",
    "cv.waitKey(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4c7842-8043-45a1-8d16-0bc399f8625b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682bed21-3beb-441c-927e-e6031d3ecca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9624ad6b-64ec-4412-be83-cab271d20a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0e6d7f-7a25-486c-8aa2-4d17e4252d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08903cc-7e60-465a-9c43-e91e7a642227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2c11c1-d674-4083-bf2e-97947470298d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e89ccaa-b556-4ed0-a512-bcfea3e04aa1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7894962-53e6-4ba7-abd6-3e76f658dbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\r"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "for i in range(100):\n",
    "    sys.stdout.write(f'{i}\\r')\n",
    "    time.sleep(0.1)\n",
    "    sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b338642-e2f3-4722-b33f-4b734bba302a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b7a5a-6048-4c60-85dc-e9527c8f8402",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
