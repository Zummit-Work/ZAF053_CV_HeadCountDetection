{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4ad9bec-08bd-4f6f-a001-6479ded59885",
   "metadata": {},
   "source": [
    "# **MediaPipe**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fcfff1-48c2-4447-88b5-26b86c6ff54b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **From official site**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dbae35-613c-4caa-a563-08fd923065b1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "    import cv2\n",
    "    import mediapipe as mp\n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "\n",
    "    # For static images:\n",
    "    IMAGE_FILES = ['sample_image.jpg']\n",
    "\n",
    "    with mp_face_detection.FaceDetection(\n",
    "        model_selection=1,\n",
    "        min_detection_confidence=0.5\n",
    "\n",
    "    ) as face_detection:\n",
    "\n",
    "        for idx, file in enumerate(IMAGE_FILES):\n",
    "            image = cv2.imread(file)\n",
    "            # Convert the BGR image to RGB and process it with MediaPipe Face Detection.\n",
    "            results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "            # Draw face detections of each face.\n",
    "            if not results.detections:\n",
    "                continue\n",
    "\n",
    "            annotated_image = image.copy()\n",
    "\n",
    "            for detection in results.detections:\n",
    "                print('Nose tip:')\n",
    "\n",
    "                print(\n",
    "                    mp_face_detection.get_key_point(\n",
    "                        detection,\n",
    "                        mp_face_detection.FaceKeyPoint.NOSE_TIP\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                mp_drawing.draw_detection(annotated_image, detection)\n",
    "\n",
    "            cv2.imwrite('A' + str(idx) + '.png', annotated_image)\n",
    "            #cv2.imwrite('/tmp/annotated_image' + str(idx) + '.png', annotated_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # For webcam input:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    with mp_face_detection.FaceDetection(\n",
    "        model_selection=0,\n",
    "        min_detection_confidence=0.5\n",
    "    ) as face_detection:\n",
    "\n",
    "        while cap.isOpened():\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                print(\"Ignoring empty camera frame.\")\n",
    "                # If loading a video, use 'break' instead of 'continue'.\n",
    "                continue\n",
    "\n",
    "            # To improve performance, optionally mark the image as not writeable to\n",
    "            # pass by reference.\n",
    "            image.flags.writeable = False\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = face_detection.process(image)\n",
    "\n",
    "            # Draw the face detection annotations on the image.\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            if results.detections:\n",
    "                for detection in results.detections:\n",
    "                    mp_drawing.draw_detection(image, detection)\n",
    "\n",
    "            # Flip the image horizontally for a selfie-view display.\n",
    "            cv2.imshow('MediaPipe Face Detection', cv2.flip(image, 1))\n",
    "\n",
    "            if cv2.waitKey(5) & 0xFF == 27:\n",
    "                break\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    # Destroy all the windows\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de526d23-f6b8-465d-869d-546f472a8994",
   "metadata": {},
   "source": [
    "### Store annotated Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8e9b286-25f3-4497-a906-b7b1f989bcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_image(img_name_list):\n",
    "    import cv2\n",
    "    import mediapipe as mp\n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    \n",
    "\n",
    "    with mp_face_detection.FaceDetection(\n",
    "        model_selection=1,\n",
    "        min_detection_confidence=0.5\n",
    "\n",
    "    ) as face_detection:\n",
    "\n",
    "        for idx, file in enumerate(img_name_list):\n",
    "            image = cv2.imread(file)\n",
    "            # Convert the BGR image to RGB and process it with MediaPipe Face Detection.\n",
    "            results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "            # Draw face detections of each face.\n",
    "            if not results.detections:\n",
    "                continue\n",
    "\n",
    "            annotated_image = image.copy()\n",
    "\n",
    "            for detection in results.detections:\n",
    "                print('Nose tip:')\n",
    "\n",
    "                print(\n",
    "                    mp_face_detection.get_key_point(\n",
    "                        detection,\n",
    "                        mp_face_detection.FaceKeyPoint.NOSE_TIP\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                mp_drawing.draw_detection(annotated_image, detection)\n",
    "\n",
    "            cv2.imwrite( file.split('.')[0] + '_annotated.png' , annotated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea28a3e1-f7ee-4fbc-b11e-ea044057dd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = ['sample_image.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d59d3abd-842f-47c8-8695-98e452f4fd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nose tip:\n",
      "x: 0.44583046436309814\n",
      "y: 0.4802980422973633\n",
      "\n",
      "Nose tip:\n",
      "x: 0.5580391883850098\n",
      "y: 0.48664039373397827\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mediapipe_image(img_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f528be15-4fa8-48a4-aee3-75e65263a0fe",
   "metadata": {},
   "source": [
    "### Show and store annotated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5a6195a-1386-4081-a9fa-edc447757e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_image_1(img_name_list):\n",
    "    import cv2\n",
    "    import mediapipe as mp\n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    \n",
    "\n",
    "    with mp_face_detection.FaceDetection(\n",
    "        model_selection=1,\n",
    "        min_detection_confidence=0.5\n",
    "\n",
    "    ) as face_detection:\n",
    "\n",
    "        for idx, file in enumerate(img_name_list):\n",
    "            image = cv2.imread(file)\n",
    "            # Convert the BGR image to RGB and process it with MediaPipe Face Detection.\n",
    "            results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "            # Draw face detections of each face.\n",
    "            if not results.detections:\n",
    "                continue\n",
    "\n",
    "            annotated_image = image.copy()\n",
    "\n",
    "            #print( list(results.detections) )\n",
    "            \n",
    "            # print the coordinates of face key points\n",
    "            for i,detection in enumerate( tuple(results.detections )):\n",
    "                print('DETECTION ',i)\n",
    "                print('  Nose tip:')\n",
    "                print(\n",
    "                    mp_face_detection.get_key_point(\n",
    "                        detection,\n",
    "                        # nose tip\n",
    "                        mp_face_detection.FaceKeyPoint.NOSE_TIP\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "                print('  Mouth center:')\n",
    "                print(\n",
    "                    mp_face_detection.get_key_point(\n",
    "                        detection,\n",
    "                        # mouth center\n",
    "                        mp_face_detection.FaceKeyPoint.MOUTH_CENTER\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                mp_drawing.draw_detection(annotated_image, detection)\n",
    "\n",
    "            cv2.imwrite( file.split('.')[0] + '_annotated.png' , annotated_image)\n",
    "            cv2.imshow(file, annotated_image)\n",
    "            cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9836be32-b68b-42cc-a086-2fd23f5daa64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETECTION  0\n",
      "  Nose tip:\n",
      "x: 0.44583046436309814\n",
      "y: 0.4802980422973633\n",
      "\n",
      "  Mouth center:\n",
      "x: 0.445222944021225\n",
      "y: 0.49528729915618896\n",
      "\n",
      "DETECTION  1\n",
      "  Nose tip:\n",
      "x: 0.5580391883850098\n",
      "y: 0.48664039373397827\n",
      "\n",
      "  Mouth center:\n",
      "x: 0.5629162788391113\n",
      "y: 0.5090557336807251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mediapipe_image_1(['sample_image.jpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46d16b-9145-4064-8b5b-7b81d0454ad3",
   "metadata": {},
   "source": [
    "### Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a75de10-8775-470a-9dcc-99ccda78f50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_webcam(my_model_selection=0, my_min_detection_confidence=0.5):\n",
    "    '''\n",
    "    Code from official website\n",
    "    '''\n",
    "    \n",
    "    import cv2\n",
    "    import mediapipe as mp\n",
    "    from warnings import warn\n",
    "    \n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    # For webcam input:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    with mp_face_detection.FaceDetection(\n",
    "        model_selection = my_model_selection,\n",
    "        min_detection_confidence = my_min_detection_confidence\n",
    "    ) as face_detection:\n",
    "\n",
    "        while cap.isOpened():\n",
    "            \n",
    "            # end feed\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "                \n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                warn('Webcam not detected.')\n",
    "                break\n",
    "                #print(\"Webcam not detected.\")\n",
    "                # If loading a video, use 'break' instead of 'continue'.\n",
    "                #continue\n",
    "\n",
    "            # To improve performance, optionally mark the image as not writeable to\n",
    "            # pass by reference.\n",
    "            image.flags.writeable = False\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = face_detection.process(image)\n",
    "\n",
    "            # Draw the face detection annotations on the image.\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            if results.detections:\n",
    "                for detection in results.detections:\n",
    "                    mp_drawing.draw_detection(image, detection)\n",
    "\n",
    "            # Flip the image horizontally for a selfie-view display.\n",
    "            cv2.imshow('MediaPipe Face Detection', cv2.flip(image, 1))\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    # Destroy all the windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "931f9f94-9275-421b-b99a-b03f34f6da3d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "mediapipe_webcam(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455422c4-f2dd-4e80-a63d-44a751e83cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570d8c4d-a320-411a-8136-fe4409eae012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b1b7e9c-6121-497e-b874-4f9829f27184",
   "metadata": {},
   "source": [
    "### Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4bd6cc3-1327-4147-93b0-c9dab9b46502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_video(filepath = 'C:/Users/afzal/Downloads/sample.mp4', my_model_selection=0, my_min_detection_confidence=0.5):\n",
    "    \n",
    "    '''\n",
    "    Code from official website\n",
    "    '''\n",
    "    import cv2\n",
    "    import mediapipe as mp\n",
    "    from warnings import warn\n",
    "    \n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    # For webcam input:\n",
    "    cap = cv2.VideoCapture(filepath)\n",
    "\n",
    "    with mp_face_detection.FaceDetection(\n",
    "        model_selection = my_model_selection,\n",
    "        min_detection_confidence = my_min_detection_confidence\n",
    "    ) as face_detection:\n",
    "\n",
    "        while cap.isOpened():\n",
    "            \n",
    "            # end feed\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "                \n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                warn('File not found.')\n",
    "                break\n",
    "                #print(\"Webcam not detected.\")\n",
    "                # If loading a video, use 'break' instead of 'continue'.\n",
    "                #continue\n",
    "\n",
    "            # To improve performance, optionally mark the image as not writeable to\n",
    "            # pass by reference.\n",
    "            image.flags.writeable = False\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = face_detection.process(image)\n",
    "\n",
    "            # Draw the face detection annotations on the image.\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            if results.detections:\n",
    "                for detection in results.detections:\n",
    "                    mp_drawing.draw_detection(image, detection,)\n",
    "\n",
    "            cv2.imshow('MediaPipe Face Detection', image)\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    # Destroy all the windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db71b0f6-c4f0-4061-8e25-17f322a49459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d27d795-bf22-4ea1-86c8-81c68f5d2140",
   "metadata": {},
   "source": [
    "#### 144p enlarged video checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "258a7978-b347-4db1-ba93-f27643b88f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:/Users/afzal/Downloads/sample_144_enlarged.mp4'\n",
    "\n",
    "mediapipe_video(filepath=filepath, my_model_selection=1, my_min_detection_confidence=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58864615-6a51-4a1f-86d1-1aaa038b7f38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5794d9a7-9d4b-4f64-b8c7-f3f1e4820f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e870e893-7c33-4846-9ea2-2e39974417ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8e3f883-89eb-45a9-9910-4182e336017e",
   "metadata": {},
   "source": [
    "# Facemesh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1a1ae3-3eb8-47cb-b350-fc9c18d46b69",
   "metadata": {},
   "source": [
    "### Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "472dbe0e-829e-4bae-b475-fa891b29cd55",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def facemesh_img(file_path=0):\n",
    "    import cv2\n",
    "    import mediapipe as mp\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_drawing_styles = mp.solutions.drawing_styles\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "    # # For static images:\n",
    "    # IMAGE_FILES = []\n",
    "    # drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "    # with mp_face_mesh.FaceMesh(\n",
    "    #     static_image_mode=True,\n",
    "    #     max_num_faces=1,\n",
    "    #     refine_landmarks=True,\n",
    "    #     min_detection_confidence=0.5) as face_mesh:\n",
    "    #   for idx, file in enumerate(IMAGE_FILES):\n",
    "    #     image = cv2.imread(file)\n",
    "    #     # Convert the BGR image to RGB before processing.\n",
    "    #     results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    #     # Print and draw face mesh landmarks on the image.\n",
    "    #     if not results.multi_face_landmarks:\n",
    "    #       continue\n",
    "    #     annotated_image = image.copy()\n",
    "    #     for face_landmarks in results.multi_face_landmarks:\n",
    "    #       print('face_landmarks:', face_landmarks)\n",
    "    #       mp_drawing.draw_landmarks(\n",
    "    #           image=annotated_image,\n",
    "    #           landmark_list=face_landmarks,\n",
    "    #           connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "    #           landmark_drawing_spec=None,\n",
    "    #           connection_drawing_spec=mp_drawing_styles\n",
    "    #           .get_default_face_mesh_tesselation_style())\n",
    "    #       mp_drawing.draw_landmarks(\n",
    "    #           image=annotated_image,\n",
    "    #           landmark_list=face_landmarks,\n",
    "    #           connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "    #           landmark_drawing_spec=None,\n",
    "    #           connection_drawing_spec=mp_drawing_styles\n",
    "    #           .get_default_face_mesh_contours_style())\n",
    "    #       mp_drawing.draw_landmarks(\n",
    "    #           image=annotated_image,\n",
    "    #           landmark_list=face_landmarks,\n",
    "    #           connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "    #           landmark_drawing_spec=None,\n",
    "    #           connection_drawing_spec=mp_drawing_styles\n",
    "    #           .get_default_face_mesh_iris_connections_style())\n",
    "    #     cv2.imwrite('/tmp/annotated_image' + str(idx) + '.png', annotated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a151483-7753-4307-b8af-aa495abcd83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def facemesh_vid(file_path=0):\n",
    "    \n",
    "    import cv2\n",
    "    import mediapipe as mp\n",
    "    \n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_drawing_styles = mp.solutions.drawing_styles\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "    \n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    \n",
    "    #############\n",
    "    print(cap)\n",
    "\n",
    "    with mp_face_mesh.FaceMesh(\n",
    "        max_num_faces=1,\n",
    "        refine_landmarks=True,\n",
    "        min_detection_confidence=0.2,\n",
    "        min_tracking_confidence=0.2\n",
    "    ) as face_mesh:\n",
    "\n",
    "        ###################\n",
    "        print(face_mesh)\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            \n",
    "            print('entering loop')\n",
    "            \n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                print('custom exit')\n",
    "                break\n",
    "\n",
    "            success, image = cap.read()\n",
    "            print(success)\n",
    "                \n",
    "            if success == False:\n",
    "                my_warning = 'Webcam not found.' if file_path==0 else 'File not found.'\n",
    "                from warnings import warn\n",
    "                warn(my_warning)\n",
    "                print('breaking')\n",
    "                break\n",
    "\n",
    "            # To improve performance, optionally mark the image as not writeable to\n",
    "            # pass by reference.\n",
    "            image.flags.writeable = False\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results = face_mesh.process(image)\n",
    "\n",
    "            # Draw the face mesh annotations on the image.\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            if results.multi_face_landmarks:\n",
    "                for face_landmarks in results.multi_face_landmarks:\n",
    "\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image=image,\n",
    "                        landmark_list=face_landmarks,\n",
    "                        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                        landmark_drawing_spec=None,\n",
    "                        connection_drawing_spec=mp_drawing_styles\n",
    "                        .get_default_face_mesh_tesselation_style()\n",
    "                    )\n",
    "\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image=image,\n",
    "                        landmark_list=face_landmarks,\n",
    "                        connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                        landmark_drawing_spec=None,\n",
    "                        connection_drawing_spec=mp_drawing_styles\n",
    "                        .get_default_face_mesh_contours_style()\n",
    "                    )\n",
    "\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image=image,\n",
    "                        landmark_list=face_landmarks,\n",
    "                        connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "                        landmark_drawing_spec=None,\n",
    "                        connection_drawing_spec=mp_drawing_styles\n",
    "                        .get_default_face_mesh_iris_connections_style()\n",
    "                    )\n",
    "\n",
    "            # Flip the image horizontally for a selfie-view display.\n",
    "            cv2.imshow(\n",
    "                'MediaPipe Face Mesh',\n",
    "                ( cv2.flip(image, 1) if file_path==0 else image )\n",
    "            )\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a62119df-67d7-4849-8791-41dcf19ca9f5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< cv2.VideoCapture 00000290544EB4F0>\n",
      "<mediapipe.python.solutions.face_mesh.FaceMesh object at 0x0000029043EE9A80>\n",
      "entering loop\n",
      "True\n",
      "entering loop\n",
      "True\n",
      "entering loop\n",
      "True\n",
      "entering loop\n",
      "True\n",
      "entering loop\n",
      "True\n",
      "entering loop\n",
      "custom exit\n"
     ]
    }
   ],
   "source": [
    "facemesh_vid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54ddbbde-5168-483c-8856-c2da963da384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< cv2.VideoCapture 00000290544E9450>\n",
      "<mediapipe.python.solutions.face_mesh.FaceMesh object at 0x0000029054466980>\n"
     ]
    }
   ],
   "source": [
    "filepath = 'C:/Users/afzal/Downloads/sample_72.mp4'\n",
    "facemesh_vid(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10981da3-e384-4daf-bf9c-0fde4f0b5a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1d8448-9a5f-4216-ac2a-3825bc54d93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4c613a4-143e-4b71-8190-4e29cb9bbe39",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Unofficial**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b095d02-3d30-4e1f-8df0-625d4171f5b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hybrid\n",
    "**working on webcam and video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d326c1a-99d2-424b-b3fe-22dd8e1d5fd9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mediapipe_hybrid(file_path=0, model=0, confidence=0.5):  \n",
    "    '''\n",
    "Webcam input\n",
    "Code from external site\n",
    "    '''\n",
    "    \n",
    "    import cv2\n",
    "    import mediapipe as mp\n",
    "    import time\n",
    "    import sys\n",
    "\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "        \n",
    "    #pTime = 0\n",
    "\n",
    "    mpFaceDetection = mp.solutions.face_detection\n",
    "    mpDraw = mp.solutions.drawing_utils\n",
    "    \n",
    "    faceDetection = mpFaceDetection.FaceDetection(\n",
    "        model_selection = model,\n",
    "        min_detection_confidence = confidence\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "        \n",
    "        success, img = cap.read()\n",
    "        \n",
    "        if success == False:\n",
    "            my_warning = 'Webcam not found.' if file_path==0 else 'File not found.'\n",
    "            from warnings import warn\n",
    "            warn(my_warning)\n",
    "            break\n",
    "        \n",
    "        img = cv2.flip(img, 1) if file_path==0 else img\n",
    "            \n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = faceDetection.process(imgRGB)      \n",
    "\n",
    "        bbox= None\n",
    "        \n",
    "        if results.detections:\n",
    "            for id, detection in enumerate(results.detections):\n",
    "                # mpDraw.draw_detection(img, detection)\n",
    "                # print(id, detection)\n",
    "                # print(detection.score)\n",
    "                # print(detection.location_data.relative_bounding_box)\n",
    "                \n",
    "                bboxC = detection.location_data.relative_bounding_box\n",
    "                ih, iw, ic = img.shape\n",
    "                \n",
    "                bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                \n",
    "                cv2.rectangle(\n",
    "                    img,\n",
    "                    bbox,\n",
    "                    (255, 0, 255),\n",
    "                    2\n",
    "                )\n",
    "                \n",
    "                cv2.putText(\n",
    "                    img,\n",
    "                    f'{ int( detection.score[0] * 100 ) }%',\n",
    "                    (bbox[0], bbox[1] - 20),\n",
    "                    cv2.FONT_HERSHEY_PLAIN,\n",
    "                    2, \n",
    "                    (255, 0, 255),\n",
    "                    2\n",
    "                )\n",
    "\n",
    "\n",
    "        sys.stdout.write(f'Coordinates: {bbox}\\r')\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        \n",
    "        # cTime = time.time()\n",
    "        # fps = 1 / (cTime - pTime)\n",
    "        # pTime = cTime\n",
    "        \n",
    "        # cv2.putText(\n",
    "        #     img,\n",
    "        #     f'FPS: { int(fps) }',\n",
    "        #     (5, 30),\n",
    "        #     cv2.FONT_HERSHEY_PLAIN,\n",
    "        #     2,\n",
    "        #     (0, 255, 0),\n",
    "        #     2\n",
    "        # )\n",
    "        \n",
    "        cv2.imshow(\"Image\", img)    \n",
    "    \n",
    "    \n",
    "    # After the loop release the cap object\n",
    "    cap.release()\n",
    "    # Destroy all the windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76d8cb8f-df33-46d4-84c5-d8b0dc24a729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates: (261, 272, 128, 128)\r"
     ]
    }
   ],
   "source": [
    "mediapipe_hybrid(model=1, confidence=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec6c4ea2-2871-49fc-9a69-8033ca5718c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates: None, 225, 54, 54)3))\r"
     ]
    }
   ],
   "source": [
    "filepath = 'C:/Users/afzal/Downloads/sample_720.mp4'\n",
    "\n",
    "mediapipe_hybrid(file_path=filepath ,model=1, confidence=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66480d3-5bc8-4d5a-955c-9c73d77c91e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Module\n",
    "**Working for webcam and video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd463c92-cbda-4384-b294-a04d32d5b1c1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "#import time\n",
    "\n",
    "\n",
    "class FaceDetector():\n",
    "    \n",
    "    def __init__(self, minDetectionCon=0.5):\n",
    "        self.minDetectionCon = minDetectionCon\n",
    "        self.mpFaceDetection = mp.solutions.face_detection\n",
    "        self.mpDraw = mp.solutions.drawing_utils\n",
    "        self.faceDetection = self.mpFaceDetection.FaceDetection(self.minDetectionCon)\n",
    "\n",
    "    def findFaces(self, img, draw=True):\n",
    "\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        self.results = self.faceDetection.process(imgRGB)\n",
    "        # print(self.results)\n",
    "        \n",
    "        bboxs = []\n",
    "        if self.results.detections:\n",
    "            for id, detection in enumerate(self.results.detections):\n",
    "                \n",
    "                bboxC = detection.location_data.relative_bounding_box\n",
    "                ih, iw, ic = img.shape\n",
    "                \n",
    "                bbox = (\n",
    "                    int(bboxC.xmin * iw),\n",
    "                    int(bboxC.ymin * ih),\n",
    "                    int(bboxC.width * iw),\n",
    "                    int(bboxC.height * ih)\n",
    "                )\n",
    "                \n",
    "                bboxs.append([id, bbox, detection.score])\n",
    "                \n",
    "                if draw:\n",
    "                    img = self.fancyDraw(img,bbox)\n",
    "                    cv2.putText(\n",
    "                        img,\n",
    "                        f'{ int(detection.score[0] * 100) }%',\n",
    "                        (bbox[0], bbox[1] - 20),\n",
    "                        cv2.FONT_HERSHEY_PLAIN,\n",
    "                        2,\n",
    "                        (255, 0, 255),\n",
    "                        2\n",
    "                    )\n",
    "        \n",
    "        return img, bboxs\n",
    "\n",
    "    def fancyDraw(self, img, bbox, l=30, t=5, rt= 1):\n",
    "        x, y, w, h = bbox\n",
    "        x1, y1 = x + w, y + h\n",
    "        cv2.rectangle(img, bbox, (255, 0, 255), rt)\n",
    "        \n",
    "        # Top Left  x,y\n",
    "        cv2.line(img, (x, y), (x + l, y), (255, 0, 255), t)\n",
    "        cv2.line(img, (x, y), (x, y+l), (255, 0, 255), t)\n",
    "        \n",
    "        # Top Right  x1,y\n",
    "        cv2.line(img, (x1, y), (x1 - l, y), (255, 0, 255), t)\n",
    "        cv2.line(img, (x1, y), (x1, y+l), (255, 0, 255), t)\n",
    "        \n",
    "        # Bottom Left  x,y1\n",
    "        cv2.line(img, (x, y1), (x + l, y1), (255, 0, 255), t)\n",
    "        cv2.line(img, (x, y1), (x, y1 - l), (255, 0, 255), t)\n",
    "        \n",
    "        # Bottom Right  x1,y1\n",
    "        cv2.line(img, (x1, y1), (x1 - l, y1), (255, 0, 255), t)\n",
    "        cv2.line(img, (x1, y1), (x1, y1 - l), (255, 0, 255), t)\n",
    "        \n",
    "        return img\n",
    "\n",
    "\n",
    "def main( file_path=0, minDetectionCon=0.5 ):\n",
    "    \n",
    "    import sys\n",
    "\n",
    "    # TAKE IN WEBCAM INPUT/VIDEO FILE AND DETECT FACE\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    \n",
    "    #pTime = 0\n",
    "    \n",
    "    detector = FaceDetector(minDetectionCon)\n",
    "    while True:\n",
    "        \n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "        \n",
    "        success, img = cap.read()\n",
    "        \n",
    "        if success == False:\n",
    "            my_warning = 'Webcam not found.' if file_path==0 else 'File not found.'\n",
    "            from warnings import warn\n",
    "            warn(my_warning)\n",
    "            break\n",
    "            \n",
    "        img = cv2.flip(img, 1) if file_path==0 else img\n",
    "        \n",
    "        img, bboxs = detector.findFaces(img)\n",
    "        \n",
    "        sys.stdout.write(f'{bboxs}\\r')\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        # cTime = time.time()\n",
    "        # fps = 1 / (cTime - pTime)\n",
    "        # pTime = cTime\n",
    "        # cv2.putText(img, f'FPS: {int(fps)}', (20, 70), cv2.FONT_HERSHEY_PLAIN, 3, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.imshow(\"Image\", img)\n",
    "        \n",
    "    # After the loop release the cap object\n",
    "    cap.release()\n",
    "    # Destroy all the windows\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5988081-01ea-43c8-8d0c-29b30d111c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, (275, 279, 113, 113), [0.9271326065063477]]]\r"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8090c6a1-cf26-4783-ad2a-801a6d61f11a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, (518, 197, 169, 169), [0.6678008437156677]]] [1, (373, 46, 188, 188), [0.9189591407775879]]]\r"
     ]
    }
   ],
   "source": [
    "filepath = 'C:/Users/afzal/Downloads/sample_720.mp4'\n",
    "main(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f629e8-34ae-4987-a690-e5c28d407a41",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Webcam only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "165abc85-1e5f-436b-845c-2752fb7b31a0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mediapipe_webcam(my_model_selection=0, my_min_detection_confidence=0.5):  \n",
    "    '''\n",
    "Webcam input\n",
    "Code from external site\n",
    "    '''\n",
    "    \n",
    "    import cv2\n",
    "    import mediapipe as mp\n",
    "    import time\n",
    "    import sys\n",
    "\n",
    "    # TAKE IN WEBCAM INPUT AND DETECT FACE\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    pTime = 0\n",
    "\n",
    "    mpFaceDetection = mp.solutions.face_detection\n",
    "    mpDraw = mp.solutions.drawing_utils\n",
    "    \n",
    "    faceDetection = mpFaceDetection.FaceDetection(\n",
    "        model_selection = my_model_selection,\n",
    "        min_detection_confidence = my_min_detection_confidence\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "        \n",
    "        success, img = cap.read()\n",
    "        \n",
    "        if success == False:\n",
    "            from warnings import warn\n",
    "            warn('Webcam not found.')\n",
    "            break\n",
    "            \n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = faceDetection.process(imgRGB)      \n",
    "\n",
    "        '''###############'''\n",
    "        #print(results.detections)\n",
    "        # sys.stdout.write(f'detections: { results.detections }\\r')\n",
    "        # sys.stdout.flush()\n",
    "        bbox= None\n",
    "        \n",
    "        if results.detections:\n",
    "            for id, detection in enumerate(results.detections):\n",
    "                # mpDraw.draw_detection(img, detection)\n",
    "                # print(id, detection)\n",
    "                # print(detection.score)\n",
    "                # print(detection.location_data.relative_bounding_box)\n",
    "                \n",
    "                bboxC = detection.location_data.relative_bounding_box\n",
    "                ih, iw, ic = img.shape\n",
    "                \n",
    "                bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                \n",
    "                cv2.rectangle(\n",
    "                    img,\n",
    "                    bbox,\n",
    "                    (255, 0, 255),\n",
    "                    2\n",
    "                )\n",
    "                \n",
    "                cv2.putText(\n",
    "                    img,\n",
    "                    f'{ int( detection.score[0] * 100 ) }%',\n",
    "                    (bbox[0], bbox[1] - 20),\n",
    "                    cv2.FONT_HERSHEY_PLAIN,\n",
    "                    2, \n",
    "                    (255, 0, 255),\n",
    "                    2\n",
    "                )\n",
    "\n",
    "                \n",
    "        '''##############'''\n",
    "        sys.stdout.write(f'Coordinates: {bbox}\\r')\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        \n",
    "        cTime = time.time()\n",
    "        fps = 1 / (cTime - pTime)\n",
    "        pTime = cTime\n",
    "        \n",
    "        cv2.putText(\n",
    "            img,\n",
    "            f'FPS: { int(fps) }',\n",
    "            (5, 30),\n",
    "            cv2.FONT_HERSHEY_PLAIN,\n",
    "            2,\n",
    "            (0, 255, 0),\n",
    "            2\n",
    "        )\n",
    "        \n",
    "        cv2.imshow(\"Image\", img)\n",
    "    \n",
    "    \n",
    "    # After the loop release the cap object\n",
    "    cap.release()\n",
    "    # Destroy all the windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6812f41c-3b4c-4512-ae5c-6354bd1e9ad0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates: (238, 270, 123, 123)\r"
     ]
    }
   ],
   "source": [
    "mediapipe_webcam(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2379180b-8458-4953-9fce-e6a766613791",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Video file only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9541ff35-fce4-4e6d-8688-776e23c58609",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mediapipe_video(filepath = 'C:/Users/afzal/Downloads/sample.mp4'):  \n",
    "    '''\n",
    "Video file input\n",
    "    '''\n",
    "    \n",
    "    import cv2\n",
    "    import mediapipe as mp\n",
    "    import time\n",
    "    import sys\n",
    "\n",
    "    # TAKE IN VIDEO INPUT AND DETECT FACE\n",
    "    \n",
    "    cap = cv2.VideoCapture(filepath)\n",
    "    pTime = 0\n",
    "\n",
    "    mpFaceDetection = mp.solutions.face_detection\n",
    "    mpDraw = mp.solutions.drawing_utils\n",
    "    faceDetection = mpFaceDetection.FaceDetection(0.75)\n",
    "\n",
    "    while True:\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "        \n",
    "        success, img = cap.read()\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = faceDetection.process(imgRGB)      \n",
    "\n",
    "        '''################'''\n",
    "        #print(results.detections)\n",
    "        # sys.stdout.write(f'detections: { results.detections }\\r')\n",
    "        # sys.stdout.flush()\n",
    "        bbox= None\n",
    "        \n",
    "        if results.detections:\n",
    "            for id, detection in enumerate(results.detections):\n",
    "                # mpDraw.draw_detection(img, detection)\n",
    "                # print(id, detection)\n",
    "                # print(detection.score)\n",
    "                # print(detection.location_data.relative_bounding_box)\n",
    "                bboxC = detection.location_data.relative_bounding_box\n",
    "                ih, iw, ic = img.shape\n",
    "                bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                cv2.rectangle(img, bbox, (255, 0, 255), 2)\n",
    "                cv2.putText(img, f'{int(detection.score[0] * 100)}%',\n",
    "                            (bbox[0], bbox[1] - 20), cv2.FONT_HERSHEY_PLAIN,\n",
    "                            2, (255, 0, 255), 2)\n",
    "\n",
    "        \n",
    "        '''##############'''\n",
    "        sys.stdout.write(f'Coordinates: {bbox}\\r')\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        \n",
    "        cTime = time.time()\n",
    "        fps = 1 / (cTime - pTime)\n",
    "        pTime = cTime\n",
    "        \n",
    "        cv2.putText(\n",
    "            img,\n",
    "            f'FPS: {int(fps)}',\n",
    "            (5,30),\n",
    "            cv2.FONT_HERSHEY_PLAIN,\n",
    "            2,\n",
    "            (0, 255, 0),\n",
    "            2\n",
    "        )\n",
    "        \n",
    "        cv2.imshow(\"Image\", img)\n",
    "    \n",
    "    \n",
    "    # After the loop release the cap object\n",
    "    cap.release()\n",
    "    # Destroy all the windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a89a843-9146-4b01-bba8-ddcf35f7bf5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates: (526, 140, 165, 165)\r"
     ]
    }
   ],
   "source": [
    "mediapipe_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6cd278-87bf-4494-8248-2d94b0d9a644",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# **-----------------Expt-----------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d8d4e88-8dd7-46a2-a9e6-9681f174026a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "filepath = 'C:/Users/afzal/Pictures/dataset/train/image_data/'\n",
    "\n",
    "img = cv.imread(filepath+'10001.jpg')\n",
    "\n",
    "cv.imshow('a window',img)\n",
    "cv.waitKey(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e89ccaa-b556-4ed0-a512-bcfea3e04aa1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7894962-53e6-4ba7-abd6-3e76f658dbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\r"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "for i in range(100):\n",
    "    sys.stdout.write(f'{i}\\r')\n",
    "    time.sleep(0.1)\n",
    "    sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec0e168-16e4-4a0a-86c1-e97a3a820359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de92e356-8a2b-473c-8b47-dd00e7660f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebde616-a124-46d1-8da6-37b146c55022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
