{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPghp96TQWGJKT4iNALR9gj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/routb68/Zummit_Infolab/blob/main/crowdcountMultiColumnConvolutionalNeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netwok creation"
      ],
      "metadata": {
        "id": "uncc0drignYg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "imc3UxNJfDgA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "\n",
        "        \n",
        "\n",
        "class Conv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, NL='relu', same_padding=False, bn=False):\n",
        "        super(Conv2d, self).__init__()\n",
        "        padding = int((kernel_size - 1) / 2) if same_padding else 0\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=padding)\n",
        "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0, affine=True) if bn else None\n",
        "        if NL == 'relu' :\n",
        "            self.relu = nn.ReLU(inplace=True) \n",
        "        elif NL == 'prelu':\n",
        "            self.relu = nn.PReLU() \n",
        "        else:\n",
        "            self.relu = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        if self.bn is not None:\n",
        "            x = self.bn(x)\n",
        "        if self.relu is not None:\n",
        "            x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class FC(nn.Module):\n",
        "    def __init__(self, in_features, out_features, NL='relu'):\n",
        "        super(FC, self).__init__()\n",
        "        self.fc = nn.Linear(in_features, out_features)\n",
        "        if NL == 'relu' :\n",
        "            self.relu = nn.ReLU(inplace=True) \n",
        "        elif NL == 'prelu':\n",
        "            self.relu = nn.PReLU() \n",
        "        else:\n",
        "            self.relu = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        if self.relu is not None:\n",
        "            x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def save_net(fname, net):\n",
        "    import h5py\n",
        "    h5f = h5py.File(fname, mode='w')\n",
        "    for k, v in net.state_dict().items():\n",
        "        h5f.create_dataset(k, data=v.cpu().numpy())\n",
        "\n",
        "\n",
        "def load_net(fname, net):\n",
        "    import h5py\n",
        "    h5f = h5py.File(fname, mode='r')\n",
        "    for k, v in net.state_dict().items():        \n",
        "        param = torch.from_numpy(np.asarray(h5f[k])) \n",
        "        v.copy_(param)\n",
        "\n",
        "\n",
        "\n",
        "def np_to_variable(x, is_cuda=True, is_training=False, dtype=torch.FloatTensor):\n",
        "    if is_training:\n",
        "        v = Variable(torch.from_numpy(x).type(dtype))\n",
        "    else:\n",
        "        v = Variable(torch.from_numpy(x).type(dtype), requires_grad = False, volatile = True)\n",
        "    if is_cuda:\n",
        "        v = v.cuda()\n",
        "    return v\n",
        "\n",
        "\n",
        "def set_trainable(model, requires_grad):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = requires_grad\n",
        "\n",
        "\n",
        "def weights_normal_init(model, dev=0.01):\n",
        "    if isinstance(model, list):\n",
        "        for m in model:\n",
        "            weights_normal_init(m, dev)\n",
        "    else:\n",
        "        for m in model.modules():            \n",
        "            if isinstance(m, nn.Conv2d):        \n",
        "                m.weight.data.normal_(0.0, dev)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.fill_(0.0)\n",
        "\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.weight.data.normal_(0.0, dev)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "models"
      ],
      "metadata": {
        "id": "yIIfHuV4hJ0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class CMTL(nn.Module):\n",
        "    '''\n",
        "    Implementation of CNN-based Cascaded Multi-task Learning of High-level Prior and Density\n",
        "    Estimation for Crowd Counting (Sindagi et al.)\n",
        "    '''\n",
        "    def __init__(self, bn=False, num_classes=10):\n",
        "        super(CMTL, self).__init__()\n",
        "        \n",
        "        self.num_classes = num_classes        \n",
        "        self.base_layer = nn.Sequential(Conv2d( 1, 16, 9, same_padding=True, NL='prelu', bn=bn),                                     \n",
        "                                        Conv2d(16, 32, 7, same_padding=True, NL='prelu', bn=bn))\n",
        "        \n",
        "        self.hl_prior_1 = nn.Sequential(Conv2d( 32, 16, 9, same_padding=True, NL='prelu', bn=bn),\n",
        "                                     nn.MaxPool2d(2),\n",
        "                                     Conv2d(16, 32, 7, same_padding=True, NL='prelu', bn=bn),\n",
        "                                     nn.MaxPool2d(2),\n",
        "                                     Conv2d(32, 16, 7, same_padding=True, NL='prelu', bn=bn),\n",
        "                                     Conv2d(16, 8,  7, same_padding=True, NL='prelu', bn=bn))\n",
        "                \n",
        "        self.hl_prior_2 = nn.Sequential(nn.AdaptiveMaxPool2d((32,32)),\n",
        "                                        Conv2d( 8, 4, 1, same_padding=True, NL='prelu', bn=bn))\n",
        "        \n",
        "        self.hl_prior_fc1 = FC(4*1024,512, NL='prelu')\n",
        "        self.hl_prior_fc2 = FC(512,256,    NL='prelu')\n",
        "        self.hl_prior_fc3 = FC(256, self.num_classes,     NL='prelu')\n",
        "        \n",
        "        \n",
        "        self.de_stage_1 = nn.Sequential(Conv2d( 32, 20, 7, same_padding=True, NL='prelu', bn=bn),\n",
        "                                     nn.MaxPool2d(2),\n",
        "                                     Conv2d(20, 40, 5, same_padding=True, NL='prelu', bn=bn),\n",
        "                                     nn.MaxPool2d(2),\n",
        "                                     Conv2d(40, 20, 5, same_padding=True, NL='prelu', bn=bn),\n",
        "                                     Conv2d(20, 10, 5, same_padding=True, NL='prelu', bn=bn))\n",
        "        \n",
        "        self.de_stage_2 = nn.Sequential(Conv2d( 18, 24, 3, same_padding=True, NL='prelu', bn=bn),\n",
        "                                        Conv2d( 24, 32, 3, same_padding=True, NL='prelu', bn=bn),                                        \n",
        "                                        nn.ConvTranspose2d(32,16,4,stride=2,padding=1,output_padding=0,bias=True),\n",
        "                                        nn.PReLU(),\n",
        "                                        nn.ConvTranspose2d(16,8,4,stride=2,padding=1,output_padding=0,bias=True),\n",
        "                                        nn.PReLU(),\n",
        "                                        Conv2d(8, 1, 1, same_padding=True, NL='relu', bn=bn))\n",
        "        \n",
        "    def forward(self, im_data):\n",
        "        x_base = self.base_layer(im_data)\n",
        "        x_hlp1 = self.hl_prior_1(x_base)\n",
        "        x_hlp2 = self.hl_prior_2(x_hlp1)\n",
        "        x_hlp2 = x_hlp2.view(x_hlp2.size()[0], -1) \n",
        "        x_hlp = self.hl_prior_fc1(x_hlp2)\n",
        "        x_hlp = F.dropout(x_hlp, training=self.training)\n",
        "        x_hlp = self.hl_prior_fc2(x_hlp)\n",
        "        x_hlp = F.dropout(x_hlp, training=self.training)\n",
        "        x_cls = self.hl_prior_fc3(x_hlp)        \n",
        "        x_den = self.de_stage_1(x_base)        \n",
        "        x_den = torch.cat((x_hlp1,x_den),1)\n",
        "        x_den = self.de_stage_2(x_den)\n",
        "        return x_den, x_cls"
      ],
      "metadata": {
        "id": "ChT4lkgzhLlt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "crowd count module"
      ],
      "metadata": {
        "id": "9IQC1KDEglts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class CrowdCounter(nn.Module):\n",
        "    def __init__(self, ce_weights=None):\n",
        "        super(CrowdCounter, self).__init__()        \n",
        "        self.CCN = CMTL()\n",
        "        if ce_weights is not None:\n",
        "            ce_weights = torch.Tensor(ce_weights)\n",
        "            ce_weights = ce_weights.cuda()\n",
        "        self.loss_mse_fn = nn.MSELoss()\n",
        "        self.loss_bce_fn = nn.BCELoss(weight=ce_weights)\n",
        "        \n",
        "    @property\n",
        "    def loss(self):\n",
        "        return self.loss_mse + 0.0001*self.cross_entropy\n",
        "    \n",
        "    def forward(self,  im_data, gt_data=None, gt_cls_label=None, ce_weights=None):        \n",
        "        im_data = np_to_variable(im_data, is_cuda=True, is_training=self.training)                        \n",
        "        density_map, density_cls_score = self.CCN(im_data)\n",
        "        density_cls_prob = F.softmax(density_cls_score)\n",
        "        \n",
        "        if self.training:                        \n",
        "            gt_data = np_to_variable(gt_data, is_cuda=True, is_training=self.training)            \n",
        "            gt_cls_label = np_to_variable(gt_cls_label, is_cuda=True, is_training=self.training,dtype=torch.FloatTensor)                        \n",
        "            self.loss_mse, self.cross_entropy = self.build_loss(density_map, density_cls_prob, gt_data, gt_cls_label, ce_weights)\n",
        "            \n",
        "            \n",
        "        return density_map\n",
        "    \n",
        "    def build_loss(self, density_map, density_cls_score, gt_data, gt_cls_label, ce_weights):\n",
        "        loss_mse = self.loss_mse_fn(density_map, gt_data)        \n",
        "        ce_weights = torch.Tensor(ce_weights)\n",
        "        ce_weights = ce_weights.cuda()\n",
        "        cross_entropy = self.loss_bce_fn(density_cls_score, gt_cls_label)\n",
        "        return loss_mse, cross_entropy\n"
      ],
      "metadata": {
        "id": "tpIA9fKqhDbK"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}